{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 20:25:53.273698: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'simulation-hawkes'\n",
    "n_sims = 10\n",
    "inputs_path = os.path.join(os.getcwd(), 'data', 'inputs')\n",
    "outputs_path = os.path.join(os.getcwd(), 'data', 'outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>event</th>\n",
       "      <th>Ask Price 1</th>\n",
       "      <th>Bid Price 1</th>\n",
       "      <th>Ask Price 2</th>\n",
       "      <th>Bid Price 2</th>\n",
       "      <th>BidDiff</th>\n",
       "      <th>AskDiff</th>\n",
       "      <th>BidDiff2</th>\n",
       "      <th>AskDiff2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>9</td>\n",
       "      <td>98.942260</td>\n",
       "      <td>co_deep_Ask</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.99</td>\n",
       "      <td>45.02</td>\n",
       "      <td>44.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>9</td>\n",
       "      <td>98.942339</td>\n",
       "      <td>co_deep_Ask</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.99</td>\n",
       "      <td>45.02</td>\n",
       "      <td>44.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>9</td>\n",
       "      <td>98.942505</td>\n",
       "      <td>co_deep_Ask</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.99</td>\n",
       "      <td>45.02</td>\n",
       "      <td>44.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>9</td>\n",
       "      <td>98.942836</td>\n",
       "      <td>co_deep_Ask</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.99</td>\n",
       "      <td>45.02</td>\n",
       "      <td>44.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>9</td>\n",
       "      <td>106.865217</td>\n",
       "      <td>co_deep_Bid</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.99</td>\n",
       "      <td>45.02</td>\n",
       "      <td>44.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date        Time        event  Ask Price 1  Bid Price 1  Ask Price 2  \\\n",
       "347     9   98.942260  co_deep_Ask         45.0        44.99        45.02   \n",
       "348     9   98.942339  co_deep_Ask         45.0        44.99        45.02   \n",
       "349     9   98.942505  co_deep_Ask         45.0        44.99        45.02   \n",
       "350     9   98.942836  co_deep_Ask         45.0        44.99        45.02   \n",
       "351     9  106.865217  co_deep_Bid         45.0        44.99        45.02   \n",
       "\n",
       "     Bid Price 2  BidDiff  AskDiff  BidDiff2  AskDiff2  \n",
       "347        44.98      0.0      0.0       0.0       0.0  \n",
       "348        44.98      0.0      0.0       0.0       0.0  \n",
       "349        44.98      0.0      0.0       0.0       0.0  \n",
       "350        44.98      0.0      0.0       0.0       0.0  \n",
       "351        44.98      0.0      0.0       0.0       0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ric = \"fake\"\n",
    "dataPath = os.path.join(outputs_path, model_name)\n",
    "dictBinnedData = {}\n",
    "for d in range(n_sims):\n",
    "    dictBinnedData[d] = []\n",
    "dates = list(dictBinnedData.keys())\n",
    "\n",
    "dfs = []\n",
    "for i in dates:\n",
    "    try:\n",
    "        read_path = os.path.join(dataPath, ric + \"_\" + str(i) + \"_12D.csv\")\n",
    "        df = pd.read_csv(read_path)\n",
    "\n",
    "        # drop columns\n",
    "        df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "        # change columns order\n",
    "        df = df[[\"Date\", \"Time\", \"event\"] + df.drop([\"Date\", \"Time\", \"event\"], axis=1).columns.to_list()]\n",
    "\n",
    "        dfs.append(df)\n",
    "    except:\n",
    "        print(f\"No data for {ric} on {i}\")\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['co_top_Ask', 'mo_Bid', 'lo_top_Bid', 'lo_inspread_Bid',\n",
       "       'lo_inspread_Ask', 'co_deep_Bid', 'mo_Ask', 'lo_deep_Bid',\n",
       "       'lo_top_Ask', 'co_top_Bid', 'co_deep_Ask', 'lo_deep_Ask'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"event\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>co_deep_Ask</th>\n",
       "      <th>co_deep_Bid</th>\n",
       "      <th>co_top_Ask</th>\n",
       "      <th>co_top_Bid</th>\n",
       "      <th>lo_deep_Ask</th>\n",
       "      <th>lo_deep_Bid</th>\n",
       "      <th>lo_inspread_Ask</th>\n",
       "      <th>lo_inspread_Bid</th>\n",
       "      <th>lo_top_Ask</th>\n",
       "      <th>lo_top_Bid</th>\n",
       "      <th>mo_Ask</th>\n",
       "      <th>mo_Bid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0.151024</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.159023</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.159032</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.159052</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.159081</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "event          co_deep_Ask  co_deep_Bid  co_top_Ask  co_top_Bid  lo_deep_Ask  \\\n",
       "Date Time                                                                      \n",
       "0    0.151024          0.0          0.0         1.0         0.0          0.0   \n",
       "     0.159023          0.0          0.0         0.0         0.0          0.0   \n",
       "     0.159032          0.0          0.0         0.0         0.0          0.0   \n",
       "     0.159052          0.0          0.0         0.0         0.0          0.0   \n",
       "     0.159081          0.0          0.0         0.0         0.0          0.0   \n",
       "\n",
       "event          lo_deep_Bid  lo_inspread_Ask  lo_inspread_Bid  lo_top_Ask  \\\n",
       "Date Time                                                                  \n",
       "0    0.151024          0.0              0.0              0.0         0.0   \n",
       "     0.159023          0.0              0.0              0.0         0.0   \n",
       "     0.159032          0.0              0.0              0.0         0.0   \n",
       "     0.159052          0.0              0.0              1.0         0.0   \n",
       "     0.159081          0.0              0.0              1.0         0.0   \n",
       "\n",
       "event          lo_top_Bid  mo_Ask  mo_Bid  \n",
       "Date Time                                  \n",
       "0    0.151024         0.0     0.0     0.0  \n",
       "     0.159023         0.0     0.0     1.0  \n",
       "     0.159032         1.0     0.0     0.0  \n",
       "     0.159052         0.0     0.0     0.0  \n",
       "     0.159081         0.0     0.0     0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df = df.copy()\n",
    "pivot_df[\"count\"] = 1\n",
    "\n",
    "pivot_df = pivot_df.pivot_table(index=[\"Date\", \"Time\"], columns=\"event\", values=\"count\").fillna(0)\n",
    "\n",
    "X = pivot_df.values\n",
    "\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3793, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-likelihood for a M-variate Hawkes Process with Exponential Excitation Kernels\n",
    "\n",
    "### 1) Single observation\n",
    "\n",
    "\n",
    "#### Intuitive Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init params\n",
    "np.random.seed(42)\n",
    "M = X.shape[1]\n",
    "T = X.shape[0]\n",
    "ts = np.arange(0, T)\n",
    "\n",
    "# model estimation params\n",
    "mu = np.random.uniform(0.1, 1.0, M)\n",
    "alpha = np.random.uniform(0.01, 0.5, (M, M))\n",
    "beta = np.random.uniform(0.5, 2.0, (M, M))\n",
    "\n",
    "# init recursive function\n",
    "R = np.zeros((M, T, M))\n",
    "\n",
    "for m in range(M):\n",
    "\n",
    "    for n in range(M):\n",
    "\n",
    "        tks = np.nonzero(X[:, m])[0]\n",
    "        tis = np.nonzero(X[:, n])[0]\n",
    "        for t in range(len(tks)):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            else:\n",
    "                tk = tks[t]\n",
    "                tkm1 = tks[t - 1]\n",
    "\n",
    "                ti = tis[tis < tk]\n",
    "                ti = ti[ti > tkm1]\n",
    "\n",
    "                sum_over_tis_given_n = 0\n",
    "                for s in range(len(ti)):\n",
    "                    if s == 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        sum_over_tis_given_n += np.exp(-beta[m, n] * (ti[s] - ti[s - 1]))\n",
    "\n",
    "                R[m, t, n] = np.exp(-beta[m, n] * (tk - tkm1)) * R[m, t - 1, n] + sum_over_tis_given_n\n",
    "\n",
    "log_likelihood = 0\n",
    "for m in range(M):\n",
    "\n",
    "     integral_term_over_t = 0\n",
    "     for n in range(M):\n",
    "          for t in ts:\n",
    "               integral_term_over_t += (alpha[m, n] / beta[m, n] * (1 - np.exp(-beta[m, n] * (T - t))))\n",
    "     integral_term_over_t = -(mu[m] * T) - integral_term_over_t\n",
    "\n",
    "     integra_term_over_countp = 0\n",
    "     for t in ts:\n",
    "          for n in range(M):\n",
    "               integra_term_over_countp += np.log(mu[n] + (alpha[m, n] * R[m, t, n]))\n",
    "\n",
    "     log_likelihood += integral_term_over_t + integra_term_over_countp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Likelihood: -566307.6579780579\n"
     ]
    }
   ],
   "source": [
    "print(f\"Log-Likelihood: {log_likelihood}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slightly Optimized Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization parameters\n",
    "np.random.seed(42)\n",
    "M = X.shape[1]\n",
    "T = X.shape[0]\n",
    "ts = np.arange(0, T)\n",
    "\n",
    "# Model estimation parameters\n",
    "mu = np.random.uniform(0.1, 1.0, M)\n",
    "alpha = np.random.uniform(0.01, 0.5, (M, M))\n",
    "beta = np.random.uniform(0.5, 2.0, (M, M))\n",
    "\n",
    "# Initialize recursive function\n",
    "R = np.zeros((M, T, M))\n",
    "\n",
    "for m in range(M):\n",
    "    for n in range(M):\n",
    "        tks = np.nonzero(X[:, m])[0]\n",
    "        tis = np.nonzero(X[:, n])[0]\n",
    "\n",
    "        # Vectorized calculation of R\n",
    "        if len(tks) > 1:\n",
    "            for t in range(1, len(tks)):\n",
    "                tk = tks[t]\n",
    "                tkm1 = tks[t - 1]\n",
    "                ti = tis[(tis > tkm1) & (tis < tk)]\n",
    "\n",
    "                sum_over_tis_given_n = 0\n",
    "                for s in range(len(ti)):\n",
    "                    if s == 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        sum_over_tis_given_n += np.exp(-beta[m, n] * (ti[s] - ti[s - 1]))\n",
    "\n",
    "                R[m, t, n] = np.exp(-beta[m, n] * (tk - tkm1)) * R[m, t - 1, n] + sum_over_tis_given_n\n",
    "\n",
    "log_likelihood = 0\n",
    "for m in range(M):\n",
    "    integral_term_over_t = 0\n",
    "    for n in range(M):\n",
    "        for t in ts:\n",
    "            integral_term_over_t += (alpha[m, n] / beta[m, n] * (1 - np.exp(-beta[m, n] * (T - t))))\n",
    "    integral_term_over_t = -(mu[m] * T) - integral_term_over_t\n",
    "\n",
    "    integra_term_over_countp = 0\n",
    "    for t in ts:\n",
    "        for n in range(M):\n",
    "            integra_term_over_countp += np.log(mu[m] + (alpha[m, n] * R[m, t, n]))\n",
    "\n",
    "    log_likelihood += integral_term_over_t + integra_term_over_countp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Likelihood: -566112.5257094807\n"
     ]
    }
   ],
   "source": [
    "print(f\"Log-Likelihood: {log_likelihood}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slightly Optimized Version - Vectorize Inner Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization parameters\n",
    "np.random.seed(42)\n",
    "M = X.shape[1]\n",
    "T = X.shape[0]\n",
    "ts = np.arange(0, T)\n",
    "\n",
    "# Model estimation parameters\n",
    "mu = np.random.uniform(0.1, 1.0, M)\n",
    "alpha = np.random.uniform(0.01, 0.5, (M, M))\n",
    "beta = np.random.uniform(0.5, 2.0, (M, M))\n",
    "\n",
    "# Initialize recursive function\n",
    "R = np.zeros((M, T, M))\n",
    "\n",
    "for m in range(M):\n",
    "    for n in range(M):\n",
    "        tks = np.nonzero(X[:, m])[0]\n",
    "        tis = np.nonzero(X[:, n])[0]\n",
    "\n",
    "        # Vectorized calculation of R\n",
    "        if len(tks) > 1:\n",
    "            for t in range(1, len(tks)):\n",
    "                tk = tks[t]\n",
    "                tkm1 = tks[t - 1]\n",
    "                ti = tis[(tis > tkm1) & (tis < tk)]\n",
    "\n",
    "                if len(ti) > 1:\n",
    "                    # Vectorized sum of exponentials\n",
    "                    ti_diff = np.diff(ti)\n",
    "                    exp_terms = np.exp(-beta[m, n] * ti_diff)\n",
    "                    sum_over_tis_given_n = np.sum(exp_terms)\n",
    "\n",
    "                    R[m, t, n] = np.exp(-beta[m, n] * (tk - tkm1)) * R[m, t - 1, n] + sum_over_tis_given_n\n",
    "                elif len(ti) == 1:\n",
    "                    R[m, t, n] = np.exp(-beta[m, n] * (tk - tkm1)) * R[m, t - 1, n] + np.exp(-beta[m, n] * (ti[0] - tkm1))\n",
    "\n",
    "log_likelihood = 0\n",
    "for m in range(M):\n",
    "    integral_term_over_t = 0\n",
    "    for n in range(M):\n",
    "        for t in ts:\n",
    "            integral_term_over_t += (alpha[m, n] / beta[m, n] * (1 - np.exp(-beta[m, n] * (T - t))))\n",
    "    integral_term_over_t = -(mu[m] * T) - integral_term_over_t\n",
    "\n",
    "    integra_term_over_countp = 0\n",
    "    for t in ts:\n",
    "        for n in range(M):\n",
    "            integra_term_over_countp += np.log(mu[m] + (alpha[m, n] * R[m, t, n]))\n",
    "\n",
    "    log_likelihood += integral_term_over_t + integra_term_over_countp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Likelihood: -566526.5973734233\n"
     ]
    }
   ],
   "source": [
    "print(f\"Log-Likelihood: {log_likelihood}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_excitation_log_likelihoodI(X, mu, alpha, beta):\n",
    "    \"\"\"\n",
    "    Computes the log-likelihood of an M-variate Hawkes process using TensorFlow.\n",
    "\n",
    "    Parameters:\n",
    "    X (np.array): Event matrix with shape (T, M), where T is the number of time steps and M is the number of dimensions.\n",
    "    mu (tf.Variable): Base intensity vector with shape (M,)\n",
    "    alpha (tf.Variable): Excitation matrix with shape (M, M)\n",
    "    beta (tf.Variable): Decay parameter matrix with shape (M, M)\n",
    "\n",
    "    Returns:\n",
    "    float: Negative log-likelihood of the Hawkes process\n",
    "    \"\"\"\n",
    "\n",
    "    M = X.shape[1]\n",
    "    T = X.shape[0]\n",
    "    ts = np.arange(0, T)\n",
    "\n",
    "    # Initialize recursive function\n",
    "    R = tf.zeros((M, T, M))\n",
    "\n",
    "    # Compute R recursively\n",
    "    for m in range(M):\n",
    "        for n in range(M):\n",
    "            tks = np.nonzero(X[:, m])[0]\n",
    "            tis = np.nonzero(X[:, n])[0]\n",
    "\n",
    "            if len(tks) > 1:\n",
    "                for t in range(1, len(tks)):\n",
    "                    tk = tks[t]\n",
    "                    tkm1 = tks[t - 1]\n",
    "                    ti = tis[(tis > tkm1) & (tis < tk)]\n",
    "\n",
    "                    sum_over_tis_given_n = 0\n",
    "                    for s in range(len(ti)):\n",
    "                        if s == 0:\n",
    "                            continue\n",
    "                        else:\n",
    "                            sum_over_tis_given_n += tf.exp(-beta[m, n] * (ti[s] - ti[s - 1]))\n",
    "\n",
    "                    R = tf.tensor_scatter_nd_update(R, [[m, t, n]], [tf.exp(-beta[m, n] * (tk - tkm1)) * R[m, t - 1, n] + sum_over_tis_given_n])\n",
    "\n",
    "    log_likelihood = 0\n",
    "    for m in range(M):\n",
    "        integral_term_over_t = 0\n",
    "        for n in range(M):\n",
    "            for t in ts:\n",
    "                integral_term_over_t += (alpha[m, n] / beta[m, n] * (1 - tf.exp(-beta[m, n] * (T - t))))\n",
    "        integral_term_over_t = -(mu[m] * T) - integral_term_over_t\n",
    "\n",
    "        integra_term_over_countp = 0\n",
    "        for t in ts:\n",
    "            for n in range(M):\n",
    "                integra_term_over_countp += tf.math.log(mu[m] + (alpha[m, n] * R[m, t, n]))\n",
    "\n",
    "        log_likelihood += integral_term_over_t + integra_term_over_countp\n",
    "\n",
    "    return -log_likelihood  # Return negative log-likelihood for minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_excitation_log_likelihoodII(X, mu, alpha, beta):\n",
    "    \"\"\"\n",
    "    Computes the log-likelihood of an M-variate Hawkes process using TensorFlow.\n",
    "\n",
    "    Parameters:\n",
    "    X (np.array): Event matrix with shape (T, M), where T is the number of time steps and M is the number of dimensions.\n",
    "    mu (tf.Variable): Base intensity vector with shape (M,)\n",
    "    alpha (tf.Variable): Excitation matrix with shape (M, M)\n",
    "    beta (tf.Variable): Decay parameter matrix with shape (M, M)\n",
    "\n",
    "    Returns:\n",
    "    float: Negative log-likelihood of the Hawkes process\n",
    "    \"\"\"\n",
    "\n",
    "    M = X.shape[1]\n",
    "    T = X.shape[0]\n",
    "    ts = np.arange(0, T)\n",
    "\n",
    "    # Initialize recursive function\n",
    "    R = tf.zeros((M, T, M))\n",
    "\n",
    "    # Compute R recursively\n",
    "    for m in range(M):\n",
    "        for n in range(M):\n",
    "            tks = np.nonzero(X[:, m])[0]\n",
    "            tis = np.nonzero(X[:, n])[0]\n",
    "\n",
    "            if len(tks) > 1:\n",
    "                for t in range(1, len(tks)):\n",
    "                    tk = tks[t]\n",
    "                    tkm1 = tks[t - 1]\n",
    "                    ti = tis[(tis > tkm1) & (tis < tk)]\n",
    "\n",
    "                    if len(ti) > 1:\n",
    "                        # Compute differences using slicing\n",
    "                        ti_diff = ti[1:] - ti[:-1]\n",
    "                        exp_terms = tf.exp(-beta[m, n] * tf.cast(ti_diff, dtype=tf.float32))\n",
    "                        sum_over_tis_given_n = tf.reduce_sum(exp_terms)\n",
    "\n",
    "                        R = tf.tensor_scatter_nd_update(R, [[m, t, n]], [tf.exp(-beta[m, n] * tf.cast((tk - tkm1), dtype=tf.float32)) * R[m, t - 1, n] + sum_over_tis_given_n])\n",
    "                    elif len(ti) == 1:\n",
    "                        sum_over_tis_given_n = tf.exp(-beta[m, n] * tf.cast((ti[0] - tkm1), dtype=tf.float32))\n",
    "                        R = tf.tensor_scatter_nd_update(R, [[m, t, n]], [tf.exp(-beta[m, n] * tf.cast((tk - tkm1), dtype=tf.float32)) * R[m, t - 1, n] + sum_over_tis_given_n])\n",
    "\n",
    "    log_likelihood = 0\n",
    "    for m in range(M):\n",
    "        integral_term_over_t = 0\n",
    "        for n in range(M):\n",
    "            for t in ts:\n",
    "                integral_term_over_t += (alpha[m, n] / beta[m, n] * (1 - tf.exp(-beta[m, n] * (T - t))))\n",
    "        integral_term_over_t = -(mu[m] * T) - integral_term_over_t\n",
    "\n",
    "        integra_term_over_countp = 0\n",
    "        for t in ts:\n",
    "            for n in range(M):\n",
    "                integra_term_over_countp += tf.math.log(mu[m] + (alpha[m, n] * R[m, t, n]))\n",
    "\n",
    "        log_likelihood += integral_term_over_t + integra_term_over_countp\n",
    "\n",
    "    return -log_likelihood  # Return negative log-likelihood for minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 20:17:06.967150: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Model initialization parameters\n",
    "X = pivot_df.values\n",
    "M = X.shape[1]\n",
    "\n",
    "# Init Model estimation parameters\n",
    "mu = tf.Variable(np.random.uniform(0.1, 1.0, M), dtype=tf.float32)\n",
    "alpha = tf.Variable(np.random.uniform(0.01, 0.5, (M, M)), dtype=tf.float32)\n",
    "beta = tf.Variable(np.random.uniform(0.5, 2.0, (M, M)), dtype=tf.float32)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Optimization step\n",
    "@tf.function\n",
    "def train_step():\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = exponential_excitation_log_likelihoodI(X, mu, alpha, beta)\n",
    "    gradients = tape.gradient(loss, [mu, alpha, beta])\n",
    "    optimizer.apply_gradients(zip(gradients, [mu, alpha, beta]))\n",
    "    return loss\n",
    "\n",
    "# Perform optimization\n",
    "for epoch in range(5):\n",
    "    loss = train_step()\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization parameters\n",
    "X = pivot_df.values\n",
    "M = X.shape[1]\n",
    "\n",
    "# Init Model estimation parameters\n",
    "mu = tf.Variable(np.random.uniform(0.1, 1.0, M), dtype=tf.float32)\n",
    "alpha = tf.Variable(np.random.uniform(0.01, 0.5, (M, M)), dtype=tf.float32)\n",
    "beta = tf.Variable(np.random.uniform(0.5, 2.0, (M, M)), dtype=tf.float32)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Optimization step\n",
    "@tf.function\n",
    "def train_step():\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = exponential_excitation_log_likelihoodII(X, mu, alpha, beta)\n",
    "    gradients = tape.gradient(loss, [mu, alpha, beta])\n",
    "    optimizer.apply_gradients(zip(gradients, [mu, alpha, beta]))\n",
    "    return loss\n",
    "\n",
    "# Perform optimization\n",
    "for epoch in range(5):\n",
    "    loss = train_step()\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
